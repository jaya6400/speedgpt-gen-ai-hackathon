### Introduction: 
- Deployment Link:

A small web app that:
- Sends the same prompt to Cerebras and to a baseline LLM (e.g., a Hugging Face endpoint running Llama)
- Measures and displays latency and response (optionally streaming tokens) side-by-side
- Produces a simple CSV/JSON results file you can show in the demo
- Tech stack used: Python, React+vite, Cerebras Api, Hugging face Api 

### Screenshot

